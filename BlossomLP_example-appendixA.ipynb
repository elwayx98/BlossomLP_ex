{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blossom LP Example - Appendix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation of Blossom LP algorithm on the example in Appendix A of \"A Detailed Introduction to a Minimum-Cost Perfect Matching Algorithm Based on Linear Programming\". This is a preliminary attempt at implementing the Blossom LP algorithm.\n",
    "\n",
    "This particular algorithm depends on networkx for implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import random as rand\n",
    "import math\n",
    "\n",
    "import timeit\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blossom LP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blossom LP Function Draft -\n",
    "# Purpose: Alg. 1 of Paper. Uses LP to solve min-cost perfect matching problem. Coined Blossom LP.\n",
    "# Input: graph G and maximum number of iterations (optional, default is 2 times number of vertices) \n",
    "# Output: edges of min-cost perfect matching. If no perfect matching, return empty set.\n",
    "#####\n",
    "# Notes: \n",
    "# - Built on Networkx, however code can possibly be generalized.\n",
    "#      - Instead of graph G a preferred input is arrays of vertices, edges, incidence matrix, and edge weights.\n",
    "# - Graph update steps, contraction and expansion, via incidence matrix manipulation and not modifying graph structure.\n",
    "\n",
    "# - Main Performance Issue: LP solver takes up about more than half of an iteration runtime (between 50% to 95%). \n",
    "\n",
    "# - Other performance improvements can be made: \n",
    "#      - Better selection and handling of data structures.\n",
    "#      - Better and fewer search operations.\n",
    "#      - Currently finds cycle edges via matrix multiplication and search. Maybe better method.\n",
    "\n",
    "\n",
    "def BlossomLP(G, max_iterations = None):\n",
    "    tol = 1e-09 # value comparison tolerance - value equal to default tolerance in math.isclose function    \n",
    "    \n",
    "    start_init = timeit.default_timer() ##### Test initialize speed\n",
    "    \n",
    "    # Initialize max_iterations\n",
    "    if max_iterations == None:\n",
    "        max_iterations = 2*G.number_of_nodes()\n",
    "    \n",
    "    # Initialize weights, Z, and blossoms\n",
    "    weights = []\n",
    "    for node1, node2, data in G.edges(data=True):\n",
    "        weights.append(data['weight'])\n",
    "    weights_adj = np.asarray(weights) # objective function parameters - weights (future versions of algorithm should try to perturb weights)\n",
    "    Z = {} # dictionary: shrunk vertices -> weight adjustments\n",
    "    blossoms = [] # list: blossom vertices lists\n",
    "    IM = nx.incidence_matrix(G) # Incidence matrix of G\n",
    "    \n",
    "    # Initialize constraint matrices\n",
    "    A_orig = IM.toarray()\n",
    "    A_orig = A_orig[A_orig.any(axis=1)] # remove row of 0s\n",
    "    num_constraints_orig = np.size(A_orig,0) # number of initial contraints for LP\n",
    "    A_pseudo = np.empty(shape = [0, G.number_of_edges()])\n",
    "    \n",
    "    # Initialize M\n",
    "    M = np.asarray([True]*num_constraints_orig) # True if vertex i in G'\n",
    "    \n",
    "    # Initialize min-cost perfect matching edges\n",
    "    matched_edges = np.array([])\n",
    "    \n",
    "    # Check if even number of vertices to match\n",
    "    if num_constraints_orig%2:\n",
    "        print(\"\\n\\nOdd number of vertices to match, n = {}. Therefore no perfect matching.\".format(num_constraints_orig))\n",
    "        return matched_edges # Return empty set\n",
    "\n",
    "    print(\"Initialization speed: \", timeit.default_timer() - start_init) #####\n",
    "    \n",
    "    iter_num = 1\n",
    "    ### While loop Start ###\n",
    "    while True:\n",
    "        print(\"\\n\\nIteration: \", iter_num)\n",
    "        print(\"weights =\", weights_adj)\n",
    "        \n",
    "        start_iter = timeit.default_timer() ##### test iteration speed\n",
    "        \n",
    "        # Inequality constraints\n",
    "        A_o = A_orig[np.where(M[:num_constraints_orig] == True)[0]]\n",
    "        b_o = np.ones(np.size(A_o,0))\n",
    "        A_p = A_pseudo[np.where(M[num_constraints_orig:] == True)]\n",
    "        b_p = np.ones(np.size(A_p,0))\n",
    "\n",
    "        # Solve LP - better LP solver?\n",
    "        \n",
    "        start_LP = timeit.default_timer() ### Performance measure - LP\n",
    "        \n",
    "        res_BLP = linprog(weights_adj, A_eq = A_o, b_eq = b_o, A_ub = -A_p, b_ub = -b_p, method = 'revised simplex')\n",
    "        \n",
    "        \n",
    "        speed_LP = timeit.default_timer() - start_LP\n",
    "        print(\"LP performance speed: \", speed_LP)\n",
    "        print(res_BLP)\n",
    "        \n",
    "        # Check if LP has solution\n",
    "        if not res_BLP.success:\n",
    "            print(\"\\n\\nNo perfect matching.\")\n",
    "            break # Return empty set\n",
    "        \n",
    "        # Check if LP solution unique. i.e. no contraction-expansion loops and alg. terminates.\n",
    "        if iter_num > max_iterations:\n",
    "            print(\"\\n\\nLP solution not unique. Try perturbing weights or changing contraction order.\")\n",
    "            break # Return empty set\n",
    "            \n",
    "        ## Check if expand else contract\n",
    "        pseudo_matchings = np.matmul(A_p,res_BLP.x) # matchings per pseudo vertex\n",
    "        isin_cycle = np.isclose(0.5, res_BLP.x) # check if matching edge in cycle\n",
    "        \n",
    "        # Expansion        \n",
    "        if (pseudo_matchings>1+tol).any(): # Check if claw exists, if so expand pseudo vertex\n",
    "            start_exp = timeit.default_timer() ##### test expansion speed\n",
    "\n",
    "            print(\"Expansion...\")\n",
    "            \n",
    "            if (pseudo_matchings>2+tol).any():\n",
    "                print(\"LP solution not unique. Restarting algorithm...\")     \n",
    "                # Reinitialize parameters\n",
    "                A_pseudo = np.empty(shape = [0, G.number_of_edges()])\n",
    "                weights_adj = np.asarray(weights) # objective function parameters - weights\n",
    "                Z = {} # dictionary: shrunk vertices -> weight adjustments\n",
    "                blossoms = [] # list: blossom vertices lists\n",
    "                M = np.asarray([True]*num_constraints_orig) # True if vertex i in G'\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            blossoms_filter = np.matmul(A_pseudo,res_BLP.x)>1+tol\n",
    "            S_i = np.where(blossoms_filter)[0][0] # Blossom vertex index\n",
    "            for v_i in blossoms[S_i]:\n",
    "                for e_i in np.where(np.append(A_orig, A_pseudo, axis = 0)[v_i,:] + A_pseudo[S_i] == 2)[0]: # Do I need tolerance? I don't think so, incidence matrix should be type integer.\n",
    "                    weights_adj[e_i] += Z[v_i]  # Update weights\n",
    "                M[v_i] = True # vertex in G'\n",
    "            M[num_constraints_orig + S_i] = False # pseudo vertex not in G' \n",
    "            \n",
    "            print(\"Expansion speed performance: \", timeit.default_timer() - start_exp) #####\n",
    "            \n",
    "        # Contraction        \n",
    "        elif isin_cycle.any(): \n",
    "            start_con = timeit.default_timer() ##### test contraction speed\n",
    "\n",
    "            print(\"Contraction...\") # If no claw and no perfect matching, then a cycle exists.\n",
    "            \n",
    "            # Tracking Cycles in script C, see paper, and picking a cycle stage.\n",
    "            C = np.array([])\n",
    "            cycles_G = np.where(isin_cycle)[0] \n",
    "            \n",
    "            # Update cycles in script C\n",
    "            if iter_num == 1:\n",
    "                cycles = cycles_G # initialize cycles in script C\n",
    "            else:\n",
    "                cycles = np.intersect1d(cycles, cycles_G, assume_unique=True) # update cycles in script C\n",
    "                C = np.setdiff1d(cycles_G, cycles, assume_unique=True) # new cycle not in script C\n",
    "                \n",
    "            if C.size == 0: # No new cycle\n",
    "                # Pick random cycle in script C\n",
    "                k = rand.randint(0, cycles.size-1)\n",
    "                C = np.array(cycles[k]) # initialize cycle C by choosing arbitrary edge in script C\n",
    "\n",
    "                # Find rest of edges in cycle C above.\n",
    "                # Computes edge adjacency matrix between C (row) and script C (column). Adds edge from script C to C if column entries sum to 1, else terminate while loop.\n",
    "                # Since odd cycle, two edges are always added to C and last two edges added are always adjacent.\n",
    "                while True: \n",
    "                    if C.size == 1:\n",
    "                        temp = np.matmul(A_orig[:, C], A_orig[:, cycles]) # C-script C edge adjacency matrix \n",
    "                        temp_edges = cycles[np.where(temp == 1)] # if edge adjacency matrix entry equals 1 then edge from script C to add to C.\n",
    "                    else:\n",
    "                        temp = np.matmul(np.transpose(A_orig[:, C]), A_orig[:, cycles]) # C-script C edge adjacency matrix \n",
    "                        temp_edges = cycles[np.where(temp.sum(axis=0) == 1)] # if edge adjancency matrix column sums to 1, then edge from script C to add to C.\n",
    "                        \n",
    "                    C = np.append(C, temp_edges) # add edges to C\n",
    "                    if A_orig[:,temp_edges].all(axis=1).any(): # Check if newly added edges are adjacent.\n",
    "                        break\n",
    "\n",
    "                # Remove chosen cycle C from script C\n",
    "                np.setdiff1d(cycles, C, assume_unique=True)\n",
    "        \n",
    "            \n",
    "            print(\"Contracted edges: \", np.asarray(G.edges)[C])\n",
    "            \n",
    "            # Build blossom and update pseudo vertex incidence matrix\n",
    "            blossoms.append(np.where(M & np.any(np.append(A_orig, A_pseudo, axis = 0)[:, C], axis=1))[0]) # add blossom vertex\n",
    "            # Update pseudo vertex incidence matrix\n",
    "            S = np.append(A_orig, A_pseudo, axis = 0)[blossoms[-1]].sum(axis = 0)\n",
    "            S[S > 1] = 0 # remove cycle edge incidences\n",
    "            A_pseudo = np.append(A_pseudo, [S], axis=0)\n",
    "            \n",
    "            # calculate z values and save them in Z\n",
    "            z_val = np.linalg.solve(np.append(A_orig, A_pseudo, axis = 0)[:, C][blossoms[-1], :], weights_adj[C])\n",
    "            \n",
    "            for i in range(0, len(blossoms[-1])):\n",
    "                v_i = blossoms[-1][i]\n",
    "                # save in Z\n",
    "                Z[v_i] = z_val[i]\n",
    "                # Update weights given Z and update M\n",
    "                for e_i in np.where(np.append(A_orig, A_pseudo, axis = 0)[v_i,:] + S == 2)[0]:\n",
    "                    weights_adj[e_i] -= z_val[i]  \n",
    "                M[v_i] = False # vertex not in G'\n",
    "            M = np.append(M, True) # new pseudo vertex in G'\n",
    "            \n",
    "            print(\"Contraction speed performance: \", timeit.default_timer() - start_con) #####\n",
    "            \n",
    "        else:\n",
    "            start_match = timeit.default_timer() ##### test matching speed\n",
    "            \n",
    "            print(\"\\n\\nFound perfect matching.\")\n",
    "            perfect_matching = res_BLP.x\n",
    "            print(\"Perfect matching with blossoms: \", np.asarray(G.edges)[np.where(np.isclose(1, res_BLP.x))])\n",
    "\n",
    "            # Check for blossoms\n",
    "            if not M[:num_constraints_orig].all():\n",
    "                # Expand blossoms and run LP on blossom original vertices excluding matched vertex.\n",
    "                unmatched_v = np.where(M[:num_constraints_orig] == False)[0] # select blossom nodes\n",
    "                unmatched_v = unmatched_v[np.where(np.isclose(0, np.matmul(A_orig[unmatched_v, :], res_BLP.x)))] # remove matched vertices\n",
    "                unmatched_e = np.where([e.all() for e in np.isin(np.array(list(G.edges())), np.asarray(G.nodes)[unmatched_v])])[0] # select unmatched edges in blossom\n",
    "                # Match unmatched edges in blossom via LP\n",
    "                unmatched_BLP = linprog(weights_adj[unmatched_e], A_eq = A_orig[unmatched_v, :][:, unmatched_e], b_eq = np.ones(len(unmatched_v)), method = 'revised simplex')\n",
    "                matched_e = unmatched_e[np.where(np.isclose(1, unmatched_BLP.x))] # indices of newly matched edges\n",
    "                perfect_matching[matched_e] = 1 # update perfect matching with matched blossom edges\n",
    "\n",
    "            # Return set of edges for perfect matching. Check for errors.\n",
    "            check = np.all(np.isclose(1, np.matmul(A_orig, perfect_matching))) # check that each vertex is incident to one edge\n",
    "            if check:\n",
    "                matched_edges = np.asarray(G.edges)[np.where(np.isclose(1, perfect_matching))] # edges of matching\n",
    "                print(\"Perfect matching incidence vector: \", perfect_matching)\n",
    "                print(\"Perfect matching edges: \", matched_edges)\n",
    "                print(\"Number of iterations: \", iter_num)\n",
    "            else:\n",
    "                print(\"Error. Not a perfect matching. Need to debug!\") ## Error message\n",
    "            \n",
    "            \n",
    "            print(\"matching performance speed: \", timeit.default_timer() - start_match) #####\n",
    "            speed_iter = timeit.default_timer() - start_iter\n",
    "            print(\"iteration performance speed: \", speed_iter) #####\n",
    "            print(\"% solve LP: {:.2f}%\".format(100*speed_LP/speed_iter) )\n",
    "            \n",
    "            break\n",
    "\n",
    "        # Update iteration number\n",
    "        iter_num += 1\n",
    "        \n",
    "         \n",
    "        speed_iter = timeit.default_timer() - start_iter\n",
    "        print(\"iteration performance speed: \", speed_iter) #####\n",
    "        print(\"% solve LP: {:.2f}%\".format(100*speed_LP/speed_iter) )\n",
    "        \n",
    "        matched_edges = np.asarray(G.edges)[np.where(np.isclose(1, res_BLP.x))] # edges of matching\n",
    "        print(\"G' matched edges: \", matched_edges)\n",
    "       \n",
    "    return matched_edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Example A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blossom LP Paper Example\n",
      "Number of nodes:  14\n",
      "Number of edges:  17\n",
      "Initialization speed:  0.002629800000022442\n",
      "\n",
      "\n",
      "Iteration:  1\n",
      "weights = [2 2 2 4 2 2 2 3 2 2 2 4 3 3 2 2 2]\n",
      "LP performance speed:  0.02274840000001177\n",
      "     con: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "     fun: 15.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 14\n",
      "   slack: array([], dtype=float64)\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.5, 0.5, 0.5, 0. , 0.5, 0.5, 0.5, 0. , 0.5, 0.5, 0.5, 0. , 1. ,\n",
      "       0. , 0.5, 0.5, 0.5])\n",
      "Contraction...\n",
      "Contracted edges:  [['l' 'm']\n",
      " ['l' 'n']\n",
      " ['m' 'n']]\n",
      "Contraction speed performance:  0.002627799999970648\n",
      "iteration performance speed:  0.029146199999956934\n",
      "% solve LP: 78.05%\n",
      "G' matched edges:  [['j' 'k']]\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "weights = [2 2 2 4 2 2 2 3 2 2 2 4 3 2 2 2 2]\n",
      "LP performance speed:  0.017694199999993998\n",
      "     con: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "     fun: 14.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 11\n",
      "   slack: array([0.])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.5, 0.5, 0.5, 0. , 0.5, 0.5, 0.5, 0. , 1. , 0. , 0. , 1. , 0. ,\n",
      "       1. , 0. , 0. , 0. ])\n",
      "Contraction...\n",
      "Contracted edges:  [['b' 'c']\n",
      " ['a' 'b']\n",
      " ['a' 'c']]\n",
      "Contraction speed performance:  0.0021043999999506013\n",
      "iteration performance speed:  0.02281649999997626\n",
      "% solve LP: 77.55%\n",
      "G' matched edges:  [['g' 'h']\n",
      " ['i' 'j']\n",
      " ['k' 'l']]\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "weights = [2 2 2 3 2 2 2 3 2 2 2 4 3 2 2 2 2]\n",
      "LP performance speed:  0.010633799999993698\n",
      "     con: array([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "     fun: 13.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 8\n",
      "   slack: array([0., 0.])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "\n",
      "\n",
      "Found perfect matching.\n",
      "Perfect matching with blossoms:  [['c' 'e']\n",
      " ['d' 'f']\n",
      " ['g' 'h']\n",
      " ['i' 'j']\n",
      " ['k' 'l']]\n",
      "Perfect matching incidence vector:  [1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "Perfect matching edges:  [['a' 'b']\n",
      " ['c' 'e']\n",
      " ['d' 'f']\n",
      " ['g' 'h']\n",
      " ['i' 'j']\n",
      " ['k' 'l']\n",
      " ['m' 'n']]\n",
      "Number of iterations:  3\n",
      "matching performance speed:  0.006314299999985451\n",
      "iteration performance speed:  0.01922130000002653\n",
      "% solve LP: 55.32%\n",
      "memory usage:  18237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kgovernor\\AppData\\Local\\Temp\\ipykernel_11464\\3789263342.py:35: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  IM = nx.incidence_matrix(G) # Incidence matrix of G\n",
      "C:\\Users\\kgovernor\\AppData\\Local\\Temp\\ipykernel_11464\\3789263342.py:74: DeprecationWarning: `method='revised simplex'` is deprecated and will be removed in SciPy 1.11.0. Please use one of the HiGHS solvers (e.g. `method='highs'`) in new code.\n",
      "  res_BLP = linprog(weights_adj, A_eq = A_o, b_eq = b_o, A_ub = -A_p, b_ub = -b_p, method = 'revised simplex')\n",
      "C:\\Users\\kgovernor\\AppData\\Local\\Temp\\ipykernel_11464\\3789263342.py:201: DeprecationWarning: `method='revised simplex'` is deprecated and will be removed in SciPy 1.11.0. Please use one of the HiGHS solvers (e.g. `method='highs'`) in new code.\n",
      "  unmatched_BLP = linprog(weights_adj[unmatched_e], A_eq = A_orig[unmatched_v, :][:, unmatched_e], b_eq = np.ones(len(unmatched_v)), method = 'revised simplex')\n"
     ]
    }
   ],
   "source": [
    "# Initialize G - Example Graph in Appendix of Paper\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(\"abcdefghijklmn\")\n",
    "G.add_edge('a', 'b', weight=2 )\n",
    "G.add_edge('a', 'c', weight=2 )\n",
    "G.add_edge('b', 'c', weight=2 )\n",
    "G.add_edge('c', 'e', weight=4 )\n",
    "G.add_edge('d', 'e', weight=2 )\n",
    "G.add_edge('d', 'f', weight=2 )\n",
    "G.add_edge('e', 'f', weight=2 )\n",
    "G.add_edge('f', 'g', weight=3 )\n",
    "G.add_edge('g', 'h', weight=2 )\n",
    "G.add_edge('g', 'i', weight=2 )\n",
    "G.add_edge('h', 'i', weight=2 )\n",
    "G.add_edge('i', 'j', weight=4 )\n",
    "G.add_edge('j', 'k', weight=3 )\n",
    "G.add_edge('k', 'l', weight=3 )\n",
    "G.add_edge('l', 'm', weight=2 )\n",
    "G.add_edge('l', 'n', weight=2 )\n",
    "G.add_edge('m', 'n', weight=2 )\n",
    "\n",
    "print(\"Blossom LP Paper Example\")\n",
    "print(\"Number of nodes: \", G.number_of_nodes())\n",
    "print(\"Number of edges: \", G.number_of_edges())\n",
    "\n",
    "tracemalloc.start()\n",
    "BlossomLP(G)\n",
    "mem = tracemalloc.get_traced_memory()\n",
    "print(\"memory usage: \", mem[1]-mem[0])\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
